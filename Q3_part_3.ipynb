{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97972cf1",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c62ef597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad5ea54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "203a5757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83b4e8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e30f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e39d919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2856b400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c59c9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7833c138",
   "metadata": {},
   "source": [
    "## (iii) Compare and comment on your results using (i) and (ii). [5 Marks]\n",
    "1. Input Format:\n",
    "\n",
    "a. The first line contains N denoting the\n",
    "number of queries to execute\n",
    "\n",
    "b. The next N lines contain phrase queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332a9b08",
   "metadata": {},
   "source": [
    "#### Load the doc map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1689145",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_PREPROCESSED_DATA= \"./preprocessed_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "073cab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_map = dict()\n",
    "\n",
    "\n",
    "for index,doc in enumerate(os.listdir(PATH_TO_PREPROCESSED_DATA)):\n",
    "    doc_map[index] = doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb5c1a6",
   "metadata": {},
   "source": [
    "##### Load the inverted bigram index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ef45695",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_SAVED = \"./Saved\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62305ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_bigram_index = \"\"\n",
    "\n",
    "with open(os.path.join(PATH_TO_SAVED,'inverted_bigram_index.pickle'),'rb') as f:\n",
    "    inverted_bigram_index = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96c92136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84208"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inverted_bigram_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa5b04d",
   "metadata": {},
   "source": [
    "#### load the pos index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "437ab6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_index = \"\"\n",
    "\n",
    "with open(os.path.join(PATH_TO_SAVED,'pos_index.pickle'),'rb') as f:\n",
    "    pos_index = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d830fa",
   "metadata": {},
   "source": [
    "#### Executing the query for positonal index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a1da8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \n",
    "    #lowercase the text\n",
    "    text = text.lower()\n",
    "\n",
    "    #remove punctuation\n",
    "    text = re.sub(r'[+*/\\\\\\-?.>,<\\\"\\';:!@#$%^&()_`~]', ' ', text)\n",
    "  \n",
    "    #tokenize\n",
    "    tokens = word_tokenize(text) #tokens will contain list of tokens\n",
    "\n",
    "    #remove stopwords\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    tokens = [token for token in tokens if token!=\" \"]\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74143dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inp():\n",
    "    \n",
    "    print(\"Execute Query ------>\\n\")\n",
    "    \n",
    "    N = int(input(\"Enter the number of queries to execute -->\"))\n",
    "\n",
    "    list_of_ip_seq = []\n",
    "\n",
    "    for i in range(N):\n",
    "        input_seq = input(\"\\nEnter the phrase query ---->\")\n",
    "        \n",
    "    list_of_ip_seq.append(input_seq)\n",
    "    \n",
    "    return list_of_ip_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2e23bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_id_for_token(token):\n",
    "        return pos_index[token][1] # will return the list of docids \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2000473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(list_of_tok):\n",
    "    \n",
    "    for tok in list_of_tok:\n",
    "        if tok not in pos_index.keys():\n",
    "            return False\n",
    "\n",
    "    return True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1edf032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_for_token(token):\n",
    "    return pos_index[token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05db825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dict(list_of_dict):\n",
    "    #takes a list of dict and return a dict\n",
    "    res = dict()\n",
    "    \n",
    "    for d in list_of_dict:\n",
    "        key = list(d.keys())[0]\n",
    "        value = list(d.values())[0]\n",
    "        res[key] = value\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6796788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_intersect(pos_list_1,pos_list_2,k):\n",
    "    ans = []\n",
    "\n",
    "    pos_list_1 = convert_to_dict(pos_list_1)\n",
    "    pos_list_2 = convert_to_dict(pos_list_2)\n",
    "    \n",
    "    \n",
    "    for doc_id in pos_list_1.keys():\n",
    "        if doc_id in pos_list_2.keys():\n",
    "            list1 = pos_list_1[doc_id]\n",
    "            list2 = pos_list_2[doc_id]\n",
    "            \n",
    "            \n",
    "            for pos1 in list1:  #### ERROR IS HEREEE\n",
    "                for pos2 in list2:\n",
    "                     \n",
    "                    if pos2 - pos1 == k:\n",
    "                        \n",
    "                        if doc_id not in ans:\n",
    "                            ans.append(doc_id)\n",
    "                        break # no need to check further in file when it is added\n",
    "        \n",
    "        \n",
    "    \n",
    "    return ans\n",
    "                        \n",
    "                    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b9dd27",
   "metadata": {},
   "source": [
    "#### Executing the query for bigram index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d52eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AND_opr(x,y):\n",
    "    \n",
    "    #note: both x and y are sorted\n",
    "    n = len(x)\n",
    "    m = len(y)\n",
    "\n",
    "    x_ptr,y_ptr=0,0\n",
    "\n",
    "    res = []\n",
    "    \n",
    "    while(x_ptr<n and y_ptr<m):\n",
    "        \n",
    "        if x[x_ptr] == y[y_ptr]:\n",
    "            res.append(x[x_ptr])\n",
    "      \n",
    "            x_ptr = x_ptr + 1\n",
    "            y_ptr = y_ptr + 1\n",
    "\n",
    "    \n",
    "        else:\n",
    "            if x[x_ptr]<y[y_ptr]:\n",
    "                x_ptr = x_ptr + 1\n",
    "            \n",
    "            else:\n",
    "                y_ptr = y_ptr + 1\n",
    "    \n",
    "    return res\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a77c6a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    list_of_queries = get_inp()\n",
    "    \n",
    "    for index,query in enumerate(list_of_queries):\n",
    "        \n",
    "        res = [] # will contain all the doc ids that fulfill pos intersect\n",
    "        \n",
    "        list_of_tokens = preprocess(query)\n",
    "        \n",
    "        #print(f\"The list of tokens {list_of_tokens}\")\n",
    "        \n",
    "        #check if the tokens in query is present in our corpus    \n",
    "        if not check(list_of_tokens):\n",
    "            print(f\"The Query {index + 1} cannot be computed as the tokens in the query do not exist in the corpus\")\n",
    "            continue #hence moving onto the next query\n",
    "    \n",
    "        \n",
    "        if len(list_of_tokens) >5:\n",
    "            print(f\"Phrase query {index + 1} has more than 5 tokens and hence cannot be processed\")\n",
    "            continue #hence continue to the next query\n",
    "        \n",
    "        \n",
    "        ## Extraction from postional index\n",
    "        for i in range(len(list_of_tokens)-1):\n",
    "            j = i + 1\n",
    "            \n",
    "            list_tok1 = get_list_for_token(list_of_tokens[i])\n",
    "            \n",
    "            dis = len(list_of_tokens[i]) # will keep of track of the next pos of the token\n",
    "            \n",
    "            while(j < len(list_of_tokens)):\n",
    "                \n",
    "                list_tok2 = get_list_for_token(list_of_tokens[j])\n",
    "                \n",
    "                k = j - i\n",
    "                \n",
    "                list_of_docs = pos_intersect(list_tok1[1],list_tok2[1],dis+k)\n",
    "                \n",
    "                res.append(list_of_docs)\n",
    "                \n",
    "                \n",
    "                dis = dis + len(list_of_tokens[j])\n",
    "                j = j + 1\n",
    "        \n",
    "\n",
    "        final_res = set(res[0])\n",
    "        for r in res[1:]:\n",
    "            final_res = final_res & set(r)\n",
    "        \n",
    "        \n",
    "        print(f\"Number of documents retrieved for query {index + 1} using positional index: {len(final_res)}\")\n",
    "        \n",
    "        file_names = []\n",
    "        for res in final_res:\n",
    "            file_names.append(doc_map[res])\n",
    "            \n",
    "        print(f\"Names of documents retrieved for query {index + 1} using positional index: {file_names}\")\n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "        ## Extraction from bigram index\n",
    "        bigrams = []\n",
    "    \n",
    "        for i in range(len(list_of_tokens)-1):\n",
    "            bigrams.append((list_of_tokens[i],list_of_tokens[i+1]))\n",
    "        \n",
    "        print(bigrams)\n",
    "        \n",
    "        res_doc_ids = inverted_bigram_index.get(bigrams[0])\n",
    "        \n",
    "        for bigram in bigrams[1:]:\n",
    "            res_doc_ids = AND_opr(res_doc_ids,inverted_bigram_index.get(bigram))\n",
    "        \n",
    "        print(f\"Number of documents retrieved for query {index + 1} using bigram inverted index: {len(res_doc_ids)}\")\n",
    "        \n",
    "        file_names = []\n",
    "        for res in final_res:\n",
    "            file_names.append(doc_map[res])\n",
    "                                  \n",
    "        print(f\"Names of documents retrieved for query {index + 1} using bigram inverted index: {file_names}\")\n",
    "        \n",
    "                    \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6a88348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('extend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad2f0165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "470"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "463+6+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01be882f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"range\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ec3f9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "476"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "463+len('extend')+len('range')+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29ec9ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('extend')+len('range')+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "224ca2a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execute Query ------>\n",
      "\n",
      "Enter the number of queries to execute -->1\n",
      "\n",
      "Enter the phrase query ---->lines method superposition linearized\n",
      "Number of documents retrieved for query 1 using positional index: 1\n",
      "Names of documents retrieved for query 1 using positional index: ['cranfield1343']\n",
      "[('lines', 'method'), ('method', 'superposition'), ('superposition', 'linearized')]\n",
      "Number of documents retrieved for query 1 using bigram inverted index: 1\n",
      "Names of documents retrieved for query 1 using bigram inverted index: ['cranfield1343']\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c96c16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c942b2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
